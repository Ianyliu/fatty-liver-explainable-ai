{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import glob\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_IMAGE_DIR = os.getenv('CROP_IMAGE_DIR_PATH')\n",
    "test_data_id = '09'\n",
    "metadata_name = 'meta_data/TWB_ABD_expand_modified_gasex_21072022.csv'\n",
    "test_data_list_name = 'fattyliver_2_class_certained_0_123_4_20_40_dataset_lists/dataset'+str(test_data_id)+'/test_dataset'+str(test_data_id)+'.csv'\n",
    "test_data_list = pd.read_csv(test_data_list_name)\n",
    "meta_data = pd.read_csv(metadata_name, sep=\",\")\n",
    "\n",
    "ground_truth_pos_mi_ids = [mi_id\n",
    "         for mi_id in test_data_list['MI_ID'] \n",
    "         if meta_data[meta_data['MI_ID']==mi_id]['liver_fatty'].to_list()[0]  > 0 ]\n",
    "selected_mi_ids = [mi_id for mi_id in ground_truth_pos_mi_ids\n",
    "                   if len(ast.literal_eval(meta_data[meta_data['MI_ID']==mi_id]['IMG_ID_LIST'].to_list()[0])) >= 20\n",
    "                   ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dirs = [\"/home/liuusa_tw/twbabd_image_xai_20062024/custom_lime_results/TEMP-elastic-net-08-02-2024-00-32-01\",\n",
    "               \"/home/liuusa_tw/twbabd_image_xai_20062024/custom_lime_results/P0012750-RIDGE-RESULTS\",\n",
    "               \"/home/liuusa_tw/twbabd_image_xai_20062024/custom_lime_results/correlation-old-dataset-08-01-2024-03-37-02\"]\n",
    "\n",
    "save_dir = \"/home/liuusa_tw/twbabd_image_xai_20062024/custom_lime_results/test_organized_output\"\n",
    "result_dict = {mi_id: {\"csv_paths\": [],\n",
    "                       \"plot_paths\": [],} \n",
    "    for mi_id in selected_mi_ids}\n",
    "for result_dir in result_dirs:\n",
    "    completed_subj = [f.name for f in os.scandir(result_dir) if f.is_dir()]\n",
    "    for mi_id in completed_subj:\n",
    "        if mi_id != \"P0012750\":\n",
    "            continue\n",
    "        glob_path = os.path.join(result_dir, mi_id)\n",
    "        if glob_path[-1] != '/':\n",
    "            glob_path = glob_path + \"/\" \n",
    "        mi_id_csvs = glob.glob(glob_path + \"*.csv\")\n",
    "        if len(mi_id_csvs) != 0: \n",
    "            result_dict[mi_id][\"csv_paths\"] += mi_id_csvs\n",
    "            \n",
    "        mi_id_img = glob.glob(glob_path + \"*.png\")\n",
    "        if len(mi_id_img) != 0: \n",
    "            result_dict[mi_id][\"plot_paths\"] += mi_id_img\n",
    "        \n",
    "img_col = \"IMG\"\n",
    "for mi_id, v in result_dict.items():\n",
    "    if mi_id != \"P0012750\":\n",
    "        continue\n",
    "    subj_dir = os.path.join(save_dir, mi_id)\n",
    "    if not os.path.exists(subj_dir):\n",
    "        os.mkdir(subj_dir)\n",
    "    v[\"dfs\"] = [pd.read_csv(csv_path) for csv_path in v[\"csv_paths\"]]\n",
    "    img_id_list = ast.literal_eval(meta_data[meta_data['MI_ID']==mi_id]['IMG_ID_LIST'].to_list()[0])\n",
    "    csv_dest_dir = os.path.join(subj_dir, \"csv\") \n",
    "    if not os.path.exists(csv_dest_dir):\n",
    "        os.mkdir(csv_dest_dir)                            \n",
    "    for indx, df in enumerate(v[\"dfs\"]):\n",
    "\n",
    "        type_dir = os.path.join(subj_dir, v[\"csv_paths\"][indx].split(\"/\")[-1].split(\".csv\")[0].split(\"_\")[0])\n",
    "        if not os.path.exists(type_dir):\n",
    "            os.mkdir(type_dir)\n",
    "            \n",
    "        if \"Estimate\" in df.columns and \"SESignificance\" in df.columns:\n",
    "            coef_col = \"Estimate\"\n",
    "            if \"IMG\" not in df.columns:\n",
    "                df[\"IMG\"] = img_id_list\n",
    "            significant_df = df.loc[df['SESignificance'] == \"SIGNIFICANT\"].copy()\n",
    "            insignificant_df = df.loc[df['SESignificance'] == \"INSIGNIFICANT\"].copy()\n",
    "            positive_df = significant_df.loc[significant_df[\"Estimate\"] > 0.0].copy()\n",
    "            negative_df = significant_df.loc[significant_df[\"Estimate\"] > 0.0].copy()\n",
    "            pass\n",
    "        elif \"corrs\" in df.columns and \"corr_significance\" in df.columns: \n",
    "            coef_col = \"corrs\"\n",
    "            significant_df = df.loc[df['corr_significance'] == \"SIGNIFICANT\"].copy()\n",
    "            insignificant_df = df.loc[df['corr_significance'] == \"INSIGNIFICANT\"].copy()\n",
    "            positive_df = significant_df.loc[significant_df[\"corrs\"] > 0.0].copy()\n",
    "            negative_df = significant_df.loc[significant_df[\"corrs\"] <  0.0].copy()\n",
    "        elif \"corr\" in df.columns and \"corr_p_val\" in df.columns: \n",
    "            v[\"dfs\"] = pd.read_csv(v[\"csv_paths\"][indx], index_col= 0)\n",
    "            df = v[\"dfs\"]\n",
    "            coef_col = \"corr\"\n",
    "            if \"IMG\" not in df.columns:\n",
    "                df[\"IMG\"] = img_id_list\n",
    "            significant_df = df.loc[df['corr_p_val'] < 0.05].copy()\n",
    "            insignificant_df = df.loc[df['corr_p_val'] >= 0.05].copy()\n",
    "            positive_df = significant_df.loc[significant_df[\"corr\"] > 0.0].copy()\n",
    "            negative_df = significant_df.loc[significant_df[\"corr\"] < 0.0].copy()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        df.to_csv(os.path.join(csv_dest_dir, f\"{indx}-\" + v[\"csv_paths\"][indx].split(\"/\")[-1]), \n",
    "                  index= None)\n",
    "        \n",
    "        positive_df = positive_df.sort_values([coef_col], ascending=[False])\n",
    "        negative_df = negative_df.sort_values([coef_col], ascending=[True])\n",
    "        positive_ranked_img = positive_df[\"IMG\"]\n",
    "        negative_ranked_img = negative_df[\"IMG\"]\n",
    "        \n",
    "        positive_img_paths = [os.path.join(CROP_IMAGE_DIR, f\"{mi_id}_{img_id}.jpg\") for img_id in positive_ranked_img]\n",
    "        negative_img_paths = [os.path.join(CROP_IMAGE_DIR, f\"{mi_id}_{img_id}.jpg\") for img_id in negative_ranked_img]\n",
    "        neutral_img_paths = [os.path.join(CROP_IMAGE_DIR, f\"{mi_id}_{img_id}.jpg\") for img_id in insignificant_df[\"IMG\"]]\n",
    "        \n",
    "        pos_img_dir = os.path.join(type_dir, \"positive/\")\n",
    "        if not os.path.exists(pos_img_dir):\n",
    "            os.mkdir(pos_img_dir)\n",
    "        neg_img_dir = os.path.join(type_dir, \"negative/\")\n",
    "        if not os.path.exists(neg_img_dir):\n",
    "            os.mkdir(neg_img_dir)\n",
    "        neutral_img_dir = os.path.join(type_dir, \"neutral/\")\n",
    "        if not os.path.exists(neutral_img_dir):\n",
    "            os.mkdir(neutral_img_dir)\n",
    "                        \n",
    "        output_positive_img_paths = [pos_img_dir + f\"{indx+1}-{i.split('/')[-1]}\" for indx, i in enumerate(positive_img_paths)]\n",
    "        output_neutral_img_paths = [neutral_img_dir + i.split('/')[-1] for _, i in enumerate(neutral_img_paths)]\n",
    "        output_negative_img_paths = [neg_img_dir + f\"{indx+1}-{i.split('/')[-1]}\" for indx, i in enumerate(negative_img_paths)]\n",
    "        \n",
    "        \n",
    "        for src_img, dest_img in zip(positive_img_paths, output_positive_img_paths):\n",
    "            shutil.copy2(src_img, dest_img)\n",
    "            \n",
    "        for src_img, dest_img in zip(neutral_img_paths, output_neutral_img_paths):\n",
    "            shutil.copy2(src_img, dest_img)\n",
    "            \n",
    "        for src_img, dest_img in zip(negative_img_paths, output_negative_img_paths):\n",
    "            shutil.copy2(src_img, dest_img)\n",
    "           \n",
    "    plot_save_dir = os.path.join(subj_dir, \"plots\")\n",
    "    if not os.path.exists(plot_save_dir):\n",
    "        os.mkdir(plot_save_dir)\n",
    "    img_save_paths = [os.path.join(plot_save_dir, f\"{indx}-\" + filepath.split(\"/\")[-1])\n",
    "                      for indx, filepath in enumerate(v[\"plot_paths\"])]\n",
    "    \n",
    "    for src_img, dest_img in zip(v[\"plot_paths\"], img_save_paths):\n",
    "        shutil.copy2(src_img, dest_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
